{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GANs(object):\n",
    "    def __init__(self, z_dim, image_dim=28 * 28):\n",
    "        self.z_dim = z_dim\n",
    "        self.image_dim = image_dim\n",
    "        self.learning_rate = 1e-4\n",
    "        self.initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "        self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        # Noise input Z\n",
    "        self.z = tf.placeholder(tf.float32, shape=[None, self.z_dim])\n",
    "\n",
    "        # Input Image\n",
    "        self.x = tf.placeholder(tf.float32, shape=[None, self.image_dim])\n",
    "\n",
    "        # Generator\n",
    "        # Take Z as an input and produce fake sample (g_sample)\n",
    "        def geneartor(z, reuse=False):\n",
    "            with tf.variable_scope(\"generator\", reuse=reuse):\n",
    "                g1 = tf.layers.dense(z, 128, activation=tf.nn.relu,\n",
    "                                     kernel_initializer=self.initializer)\n",
    "                g_prob = tf.layers.dense(g1, self.image_dim, activation=tf.nn.sigmoid,\n",
    "                                         kernel_initializer=self.initializer)\n",
    "\n",
    "                return g_prob\n",
    "\n",
    "        # Discriminator\n",
    "        # A classifier returning probability of being a real example\n",
    "        def discriminator(x, reuse=False):\n",
    "            with tf.variable_scope(\"discriminator\", reuse=reuse):\n",
    "                d1 = tf.layers.dense(x, 128, activation=tf.nn.relu,\n",
    "                                     kernel_initializer=self.initializer)\n",
    "                d_logit = tf.layers.dense(d1, 1, activation=None, kernel_initializer=self.initializer)\n",
    "                d_prob = tf.nn.sigmoid(d_logit)\n",
    "                return d_prob, d_logit\n",
    "\n",
    "        # logit output from discriminator for real example\n",
    "        D_prob_real, D_logit_real = discriminator(self.x)\n",
    "\n",
    "        # generate fake sample from generator\n",
    "        self.g_sample = geneartor(self.z)\n",
    "        # logit output from discriminator for fake example\n",
    "        D_prob_fake, D_logit_fake = discriminator(self.g_sample, reuse=True)\n",
    "\n",
    "        # Defining losses\n",
    "  \n",
    "        # Discriminator Loss\n",
    "        self.D_loss = ???\n",
    "\n",
    "        # Generator Loss\n",
    "        self.G_loss = ???\n",
    "        \n",
    "        # Obtain variables relevant to discriminator and geneartor\n",
    "        D_var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "        G_var_list = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "\n",
    "        self.D_train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.D_loss, var_list=D_var_list)\n",
    "        self.G_train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.G_loss, var_list=G_var_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "Z_dim = 128\n",
    "\n",
    "f_mnist = input_data.read_data_sets('../data/fashion_mnist')\n",
    "\n",
    "gan = GANs(Z_dim)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "if not os.path.exists('out/'):\n",
    "    os.makedirs('out/')\n",
    "\n",
    "i = 0\n",
    "for it in range(100000):\n",
    "    if it % 1000 == 0:\n",
    "        samples = sess.run(gan.generator_z, feed_dict={gan.z: sample_z_uniform(16, Z_dim)})\n",
    "\n",
    "        fig = plot(samples)\n",
    "        plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    "\n",
    "    x_image, _ = f_mnist.train.next_batch(batch_size)\n",
    "\n",
    "    _, D_loss_curr = sess.run([gan.D_train_op, gan.D_loss],\n",
    "                              feed_dict={gan.x: x_image, gan.z: sample_z_uniform(batch_size, Z_dim)})\n",
    "    _, G_loss_curr = sess.run([gan.G_train_op, gan.G_loss], feed_dict={gan.z: sample_z_uniform(batch_size, Z_dim)})\n",
    "\n",
    "    if it % 1000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'.format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
